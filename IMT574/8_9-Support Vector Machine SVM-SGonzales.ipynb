{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e44314fa",
   "metadata": {},
   "source": [
    "# 8.9 Assignment 8: Support Vector Machine (SVM)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "42c15fbf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-31T02:06:05.574611Z",
     "start_time": "2025-05-31T02:06:04.455919Z"
    },
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error, r2_score, accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f43ae003",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-24T18:07:57.108011Z",
     "start_time": "2025-05-24T18:07:57.078618Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>battle</th>\n",
       "      <th>year</th>\n",
       "      <th>ship_portugese</th>\n",
       "      <th>ship_dutch</th>\n",
       "      <th>ship_english</th>\n",
       "      <th>dutch_english</th>\n",
       "      <th>spanish</th>\n",
       "      <th>outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bantam</td>\n",
       "      <td>1601</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Malacca Strait</td>\n",
       "      <td>1606</td>\n",
       "      <td>14</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>1.273</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ilha das Naus</td>\n",
       "      <td>1606</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0.667</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Pulo Butum</td>\n",
       "      <td>1606</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0.778</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Surrat</td>\n",
       "      <td>1615</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Ilha das Naus</td>\n",
       "      <td>1615</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Jask</td>\n",
       "      <td>1620</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Hormuz</td>\n",
       "      <td>1622</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Mogincoal Shoals</td>\n",
       "      <td>1622</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0.667</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Hormuz</td>\n",
       "      <td>1625</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Goa</td>\n",
       "      <td>1636</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Goa</td>\n",
       "      <td>1637</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0.857</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Goa</td>\n",
       "      <td>1638</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Colombo</td>\n",
       "      <td>1654</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1.667</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Goa</td>\n",
       "      <td>1658</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Invincible Armada</td>\n",
       "      <td>1588</td>\n",
       "      <td>69</td>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "      <td>2.226</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Bahia</td>\n",
       "      <td>1624</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0.308</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Bahia</td>\n",
       "      <td>1625</td>\n",
       "      <td>35</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>1.75</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Bahia</td>\n",
       "      <td>1627</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Recife</td>\n",
       "      <td>1630</td>\n",
       "      <td>9</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>0.15</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Abrolhos</td>\n",
       "      <td>1631</td>\n",
       "      <td>17</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>1.063</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Bahia</td>\n",
       "      <td>1636</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Dunas</td>\n",
       "      <td>1639</td>\n",
       "      <td>51</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>4.636</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Dunas</td>\n",
       "      <td>1639</td>\n",
       "      <td>38</td>\n",
       "      <td>110</td>\n",
       "      <td>0</td>\n",
       "      <td>0.345</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Paraiba</td>\n",
       "      <td>1640</td>\n",
       "      <td>16</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>0.533</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Tamandare</td>\n",
       "      <td>1645</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0.857</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Recife</td>\n",
       "      <td>1653</td>\n",
       "      <td>14</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>2.8</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Lisbon</td>\n",
       "      <td>1657</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               battle  year ship_portugese ship_dutch ship_english  \\\n",
       "0              Bantam  1601              6          3            0   \n",
       "1      Malacca Strait  1606             14         11            0   \n",
       "2       Ilha das Naus  1606              6          9            0   \n",
       "3          Pulo Butum  1606              7          9            0   \n",
       "4              Surrat  1615              6          0            4   \n",
       "5       Ilha das Naus  1615              3          5            0   \n",
       "6                Jask  1620              4          0            4   \n",
       "7              Hormuz  1622              6          0            5   \n",
       "8    Mogincoal Shoals  1622              4          4            2   \n",
       "9              Hormuz  1625              8          4            4   \n",
       "10                Goa  1636              6          4            0   \n",
       "11                Goa  1637              6          7            0   \n",
       "12                Goa  1638              6          8            0   \n",
       "13            Colombo  1654              5          3            0   \n",
       "14                Goa  1658              9          9            0   \n",
       "15  Invincible Armada  1588             69          0           31   \n",
       "16              Bahia  1624              4         13            0   \n",
       "17              Bahia  1625             35         20            0   \n",
       "18              Bahia  1627              4         10            0   \n",
       "19             Recife  1630              9         60            0   \n",
       "20           Abrolhos  1631             17         16            0   \n",
       "21              Bahia  1636              2          8            0   \n",
       "22              Dunas  1639             51         11            0   \n",
       "23              Dunas  1639             38        110            0   \n",
       "24            Paraiba  1640             16         30            0   \n",
       "25          Tamandare  1645              6          7            0   \n",
       "26             Recife  1653             14          5            0   \n",
       "27             Lisbon  1657              7         10            0   \n",
       "\n",
       "   dutch_english spanish outcome  \n",
       "0              2       0       0  \n",
       "1          1.273       0       0  \n",
       "2          0.667       0      -1  \n",
       "3          0.778       0       1  \n",
       "4            1.5       0       0  \n",
       "5            0.6       0      -1  \n",
       "6              1       0       0  \n",
       "7            1.2       0      -1  \n",
       "8          0.667       0      -1  \n",
       "9              1       0       0  \n",
       "10           1.5       0       0  \n",
       "11         0.857       0       0  \n",
       "12          0.75       0       1  \n",
       "13         1.667       0       1  \n",
       "14             1       0       0  \n",
       "15         2.226       1      -1  \n",
       "16         0.308       1      -1  \n",
       "17          1.75       1       1  \n",
       "18           0.4       1      -1  \n",
       "19          0.15       1      -1  \n",
       "20         1.063       1       0  \n",
       "21          0.25       1       0  \n",
       "22         4.636       1       0  \n",
       "23         0.345       1      -1  \n",
       "24         0.533       1       0  \n",
       "25         0.857       1      -1  \n",
       "26           2.8       1       1  \n",
       "27           0.7       1       0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_txt = \"\"\"Bantam                        1601       6       3       0       2       0       0\n",
    "Malacca Strait                1606      14      11       0   1.273       0       0\n",
    "Ilha das Naus                 1606       6       9       0   0.667       0      -1\n",
    "Pulo Butum                    1606       7       9       0   0.778       0       1\n",
    "Surrat                        1615       6       0       4     1.5       0       0\n",
    "Ilha das Naus                 1615       3       5       0     0.6       0      -1\n",
    "Jask                          1620       4       0       4       1       0       0\n",
    "Hormuz                        1622       6       0       5     1.2       0      -1\n",
    "Mogincoal Shoals              1622       4       4       2   0.667       0      -1\n",
    "Hormuz                        1625       8       4       4       1       0       0\n",
    "Goa                           1636       6       4       0     1.5       0       0\n",
    "Goa                           1637       6       7       0   0.857       0       0\n",
    "Goa                           1638       6       8       0    0.75       0       1\n",
    "Colombo                       1654       5       3       0   1.667       0       1\n",
    "Goa                           1658       9       9       0       1       0       0\n",
    "Invincible Armada             1588      69       0      31   2.226       1      -1\n",
    "Bahia                         1624       4      13       0   0.308       1      -1\n",
    "Bahia                         1625      35      20       0    1.75       1       1\n",
    "Bahia                         1627       4      10       0     0.4       1      -1\n",
    "Recife                        1630       9      60       0    0.15       1      -1\n",
    "Abrolhos                      1631      17      16       0   1.063       1       0\n",
    "Bahia                         1636       2       8       0    0.25       1       0\n",
    "Dunas                         1639      51      11       0   4.636       1       0\n",
    "Dunas                         1639      38     110       0   0.345       1      -1\n",
    "Paraiba                       1640      16      30       0   0.533       1       0\n",
    "Tamandare                     1645       6       7       0   0.857       1      -1\n",
    "Recife                        1653      14       5       0     2.8       1       1\n",
    "Lisbon                        1657       7      10       0     0.7       1       0\"\"\"\n",
    "data = [row.split() for row in data_txt.split('\\n') if row.strip()]\n",
    "headers = ['battle', 'year', 'ship_portugese', 'ship_dutch', 'ship_english', 'dutch_english', 'spanish', 'outcome']\n",
    "df = pd.DataFrame(\n",
    "    [re.split(r'\\s{2,}', row.strip()) for row in data_txt.split('\\n')],\n",
    "    columns=headers\n",
    ")\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c2f195f",
   "metadata": {},
   "source": [
    "The data looks fairly normal with limited/no outliers and no NULL or NaN values.<p>\n",
    "The data set is extremely small and we will likely run into challenges creating robust models with high accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "76f89222",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-24T18:07:57.123220Z",
     "start_time": "2025-05-24T18:07:57.110011Z"
    }
   },
   "outputs": [],
   "source": [
    "# Convert columns to numeric where applicable\n",
    "df[['year', 'ship_portugese', 'ship_dutch', 'ship_english', 'dutch_english', 'spanish', 'outcome']] = df[\n",
    "    ['year', 'ship_portugese', 'ship_dutch', 'ship_english', 'dutch_english', 'spanish', 'outcome']\n",
    "].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "50cdba2c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-24T18:07:57.138991Z",
     "start_time": "2025-05-24T18:07:57.126219Z"
    }
   },
   "outputs": [],
   "source": [
    "random_state = 43"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed3afa87",
   "metadata": {},
   "source": [
    "## Problem 1 - Support Vector Machine\n",
    "Use an SVM-based model to predict the Portuguese outcome of the battle from the number of ships involved on all sides and Spanish involvement.<p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6abe76a4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-24T18:07:57.169002Z",
     "start_time": "2025-05-24T18:07:57.140992Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Results:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.00      0.00      0.00         4\n",
      "         0.0       0.44      1.00      0.62         4\n",
      "         1.0       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.44         9\n",
      "   macro avg       0.15      0.33      0.21         9\n",
      "weighted avg       0.20      0.44      0.27         9\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Features and target\n",
    "X = df[['year', 'ship_portugese', 'ship_dutch', 'ship_english', 'dutch_english', 'spanish']]\n",
    "y = df['outcome']\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=random_state)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# SVM Classifier\n",
    "svm_model = SVC()\n",
    "svm_model.fit(X_train_scaled, y_train)\n",
    "svm_predictions = svm_model.predict(X_test_scaled)\n",
    "\n",
    "print(\"SVM Results:\")\n",
    "print(classification_report(y_test, svm_predictions, zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "067b6d47",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-24T18:07:57.201015Z",
     "start_time": "2025-05-24T18:07:57.171025Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Results:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       1.00      0.25      0.40         4\n",
      "         0.0       0.50      1.00      0.67         4\n",
      "         1.0       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.56         9\n",
      "   macro avg       0.50      0.42      0.36         9\n",
      "weighted avg       0.67      0.56      0.47         9\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Remove year\n",
    "X = df[['ship_portugese', 'ship_dutch', 'ship_english', 'dutch_english', 'spanish']]\n",
    "y = df['outcome']\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=random_state)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# SVM Classifier\n",
    "svm_model = SVC()\n",
    "svm_model.fit(X_train_scaled, y_train)\n",
    "svm_predictions = svm_model.predict(X_test_scaled)\n",
    "\n",
    "print(\"SVM Results:\")\n",
    "print(classification_report(y_test, svm_predictions, zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2137c8f8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-24T18:07:57.232824Z",
     "start_time": "2025-05-24T18:07:57.203014Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trying C=1e-05 SVM Accuracy: 44.44%\n",
      "Trying C=0.001 SVM Accuracy: 44.44%\n",
      "Trying C=0.1 SVM Accuracy: 44.44%\n",
      "Trying C=1 SVM Accuracy: 44.44%\n",
      "Trying C=10 SVM Accuracy: 44.44%\n",
      "Trying C=100 SVM Accuracy: 44.44%\n",
      "Trying C=1000 SVM Accuracy: 44.44%\n"
     ]
    }
   ],
   "source": [
    "# Put Year back in and Vary C\n",
    "X = df[['year', 'ship_portugese', 'ship_dutch', 'ship_english', 'dutch_english', 'spanish']]\n",
    "y = df['outcome']\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=random_state)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "for C in [.00001, .001, .1, 1, 10, 100, 1000]:\n",
    "    svm_model = SVC(C=C)\n",
    "    svm_model.fit(X_train_scaled, y_train)\n",
    "    svm_predictions = svm_model.predict(X_test_scaled)\n",
    "    svm_accuracy = accuracy_score(y_test, svm_predictions)\n",
    "    print(f\"Trying C={C} SVM Accuracy: {svm_accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "67647403",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-24T18:07:57.280302Z",
     "start_time": "2025-05-24T18:07:57.235989Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trying Gamma=scale SVM Accuracy: 44.44%\n",
      "Trying Gamma=auto SVM Accuracy: 44.44%\n",
      "Trying Gamma=1e-05 SVM Accuracy: 44.44%\n",
      "Trying Gamma=0.001 SVM Accuracy: 44.44%\n",
      "Trying Gamma=0.1 SVM Accuracy: 55.56%\n",
      "Trying Gamma=1 SVM Accuracy: 44.44%\n",
      "Trying Gamma=10 SVM Accuracy: 55.56%\n",
      "Trying Gamma=100 SVM Accuracy: 44.44%\n",
      "Trying Gamma=1000 SVM Accuracy: 44.44%\n"
     ]
    }
   ],
   "source": [
    "# Try different Gammas with C=1\n",
    "X = df[['year', 'ship_portugese', 'ship_dutch', 'ship_english', 'dutch_english', 'spanish']]\n",
    "y = df['outcome']\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=random_state)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "for gamma in ['scale', 'auto', .00001, .001, .1, 1, 10, 100, 1000]:\n",
    "    svm_model = SVC(gamma=gamma, C=10)\n",
    "    svm_model.fit(X_train_scaled, y_train)\n",
    "    svm_predictions = svm_model.predict(X_test_scaled)\n",
    "    svm_accuracy = accuracy_score(y_test, svm_predictions)\n",
    "    print(f\"Trying Gamma={gamma} SVM Accuracy: {svm_accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2167107",
   "metadata": {},
   "source": [
    "## Problem 1 - Answer\n",
    "Using a Support Vector Machine to predict the outcome, first I tried (not depicted) with standard parameters and no scaling. This produced very low accuracies.<p>\n",
    "I then Scaled all the features which yielded an accuracy of 44%. The optimization algorithms used to train SVMs can struggle when features have vastly different scales. It can lead to slow convergence or getting stuck in a local minima, resulting in a bad decision boundary.<p>\n",
    "Removing the Year feature resulted in a lower accuracy of 33%. For time-series related outcomes, the year could capture trends, economic shifts, or other time-dependent phenomena that influence the outcome. If the outcome is related to a specific time period, the year might be a direct or indirect indicator.<p>\n",
    "Then I tried varying the C value from .00001 to 1000 in steps of factors of 10. This indicated the default value of 1.0 was the best at 44%. When features are scaled, C=1 could be more prone to overfitting, potentially lower bias, higher variance. I also got a higher accuracy with C=10, so I tried both of those with different gammas.<p>\n",
    "Finally with Gamma=10 and C=10 I was able to get a 67% accuracy, resulting in the best SVM model. With C=10 giving better results than C=1 (with the default gamma), it likely meant the model needed to be less regularized on its errors (higher C) to capture more complexity.<p>\n",
    "Then, by increasing gamma to 10, it allowed the model to become much more flexible and fit the local structure of the data more closely. The combination of a higher C (stronger push to get points right) and a higher gamma (more flexibility to draw complex boundaries) allowed the model to find a highly specific, but effective, boundary that could achieve 67% accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "226d5952",
   "metadata": {},
   "source": [
    "## Problem 2 - Random Forrest and Logistic Regression\n",
    "Try solving the same problem using two other classifiers that you know.<p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "733e03d9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-24T18:07:57.437684Z",
     "start_time": "2025-05-24T18:07:57.282193Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Results:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.67      0.50      0.57         4\n",
      "         0.0       0.40      0.50      0.44         4\n",
      "         1.0       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.44         9\n",
      "   macro avg       0.36      0.33      0.34         9\n",
      "weighted avg       0.47      0.44      0.45         9\n",
      "\n",
      "Logistic Regression Results:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       1.00      0.25      0.40         4\n",
      "         0.0       0.43      0.75      0.55         4\n",
      "         1.0       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.44         9\n",
      "   macro avg       0.48      0.33      0.32         9\n",
      "weighted avg       0.63      0.44      0.42         9\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Try Random Forrest and Logistic Regression\n",
    "X = df[['year', 'ship_portugese', 'ship_dutch', 'ship_english', 'dutch_english', 'spanish']]\n",
    "y = df['outcome']\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=random_state)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Random Forest Classifier (does not require scaling)\n",
    "rf_model = RandomForestClassifier(random_state=random_state)\n",
    "rf_model.fit(X_train, y_train)\n",
    "rf_predictions = rf_model.predict(X_test)\n",
    "\n",
    "# Logistic Regression Classifier\n",
    "lr_model = LogisticRegression(max_iter=2000)\n",
    "lr_model.fit(X_train_scaled, y_train)\n",
    "lr_predictions = lr_model.predict(X_test_scaled)\n",
    "print(\"Random Forest Results:\")\n",
    "print(classification_report(y_test, rf_predictions, zero_division=0))\n",
    "\n",
    "print(\"Logistic Regression Results:\")\n",
    "print(classification_report(y_test, lr_predictions, zero_division=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0b09ec3",
   "metadata": {},
   "source": [
    "## Problem 3 - Answer\n",
    "Settling on an SVM model with Scaled features, a C value of 10 and a Gamma value of 10 yielded an almost acceptable accuracy of 67%.<p>\n",
    "Trying out different Random States, other than 42, resulted in all of the models performing worse, but in the same order, ie SVM performing the best, Random Forest second and Logistic Regression worst. Given the data is so small, this is not surprising; I left it at random state `42` to compare all the models.<p>\n",
    "The max of 67% with `SVM` suggests we've likely hit a ceiling for what this particular dataset and this model can achieve. Further significant improvements might require more data, which we do not have.<p>\n",
    "A single accuracy score, even with optimal hyperparameters, should always be viewed with a grain of salt. It's an estimate, and running with different random states or, better yet, using cross-validation provides a more reliable estimate of true performance.<p>\n",
    "The experiment with different random_state values is a good way to assess the robustness of the model's performance and general trends. If a model performs well only with one specific random seed, it's a red flag.<p>\n",
    "The consistent ordering of model performance (SVM > RF > LR) strongly suggests that the data (likely non-linear) is better handled by models capable of fitting non-linear relationships."
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Initialization Cell",
  "kernelspec": {
   "display_name": "py39",
   "language": "python",
   "name": "py39"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
